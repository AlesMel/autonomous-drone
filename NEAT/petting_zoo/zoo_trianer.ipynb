{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PettingZoo, UnityEnviroment and python-neat\n",
    "<p> This is a trainer for autonomous drone enviroment </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.environment import UnityEnvironment  # Import Unity environment\n",
    "from mlagents_envs.envs.unity_aec_env import UnityAECEnv\n",
    "from mlagents_envs.envs.unity_parallel_env import UnityParallelEnv\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "from comunication_channel import AgentLogChannel\n",
    "import neat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine_config_channel = EngineConfigurationChannel()\n",
    "engine_config_channel.set_configuration_parameters(time_scale=1)\n",
    "agent_count_channel = AgentLogChannel()\n",
    "env_file_name = \"..\\\\Builds\\\\single-agent-env\\\\autonomous-drone.exe\"\n",
    "env = UnityEnvironment(file_name=env_file_name, worker_id=0, no_graphics=True, side_channels=[engine_config_channel, agent_count_channel])\n",
    "\n",
    "env = UnityParallelEnv(env)\n",
    "num_agents = len(env.possible_agents)\n",
    "num_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.2357119e-10,  3.0008994e-02,  1.1849005e-09,  3.0008994e-02,\n",
       "        1.1967495e-07,  0.0000000e+00,  1.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00, -9.7397842e-02,  0.0000000e+00,  0.0000000e+00,\n",
       "       -1.9296518e-01,  0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(obs.values())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_num_agents(num: int):\n",
    "    agent_count_channel.send_int(data=num)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending: 2\n"
     ]
    }
   ],
   "source": [
    "# Test sending data\n",
    "targetAgentsCount = 2\n",
    "send_num_agents(targetAgentsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "assert len(obs) == targetAgentsCount, \"Dictionary does not have exactly 2 items\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is total of 4 actions in enviroment\n"
     ]
    }
   ],
   "source": [
    "num_actions = env.action_space(env.possible_agents[0]).shape[0]\n",
    "print(f\"There is total of {num_actions} actions in enviroment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is total of 14 inputs in enviroment\n"
     ]
    }
   ],
   "source": [
    "num_inputs = env.observation_space(env.possible_agents[0]).shape[0]\n",
    "print(f\"There is total of {num_inputs} inputs in enviroment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create policies here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genome(genome, config):\n",
    "    print(\"Evaluating genome\")\n",
    "    # net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "    # while env.agents:\n",
    "    #     actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
    "    #     observations, rewards, terminations, infos = env.step(actions)\n",
    "    # print(rewards)\n",
    "    # env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, config):\n",
    "    print(\"Evaluating genomes\")\n",
    "    for _, genome in genomes:\n",
    "        genome.fitness = eval_genome(genome, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    print(\"Came into run\")\n",
    "\n",
    "    config_path = \"config\"\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_path)\n",
    "\n",
    "    pop = neat.Population(config)\n",
    "    stats = neat.StatisticsReporter()\n",
    "    pop.add_reporter(stats)\n",
    "    print(\"Starting\")\n",
    "\n",
    "    pe = neat.ParallelEvaluator(6, eval_genomes)\n",
    "    winner = pop.run(pe.evaluate, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending: 1\n"
     ]
    }
   ],
   "source": [
    "target_agents = 1\n",
    "send_num_agents(target_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num agents after reset: 1\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "agents = env.reset()\n",
    "print(f\"Num agents after reset: {len(agents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending: 37\n",
      "Num agents after reset: 37, and env has: 37\n",
      "Num rewards after: {'RotorControl?team=0?agent_id=36': -0.96860385}\n",
      "Sending: 46\n",
      "Num agents after reset: 46, and env has: 46\n",
      "Num rewards after: {'RotorControl?team=0?agent_id=18': -0.99782336}\n",
      "Sending: 28\n",
      "Num agents after reset: 28, and env has: 28\n",
      "Num rewards after: {'RotorControl?team=0?agent_id=23': -22.101067}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "for i in range(3):\n",
    "    target_agents = random.randint(1, 50)\n",
    "    send_num_agents(target_agents)\n",
    "    env.reset()\n",
    "    agents = env.reset()\n",
    "    print(f\"Num agents after reset: {len(agents)}, and env has: {len(env.agents)}\")\n",
    "    while env.agents:\n",
    "        actions = {agent: env.action_space(agent).sample()  for agent in env.agents} # env.action_space(agent).sample()\n",
    "        observations, rewards, terminations, infos = env.step(actions)\n",
    "    print(f\"Num rewards after: {rewards}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
