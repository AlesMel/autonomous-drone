{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import neat\n",
    "import datetime\n",
    "import os\n",
    "import math\n",
    "\n",
    "from comunication_channel import AgentLogChannel\n",
    "\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from mlagents_envs.base_env import ActionTuple\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "NUM_RUNS = 5\n",
    "MAX_GENS = 3000\n",
    "\n",
    "generation = 0\n",
    "SAVE_INTERVAL = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "engine_config_channel = EngineConfigurationChannel()\n",
    "engine_config_channel.set_configuration_parameters(time_scale=4)\n",
    "agent_count_channel = AgentLogChannel()\n",
    "\n",
    "env_path = \"../Builds/train-env/autonomous-drone.exe\"\n",
    "save_nn_destination = 'result/best.pkl'\n",
    "\n",
    "env = UnityEnvironment(file_name=None, worker_id=0, no_graphics=True, side_channels=[engine_config_channel, agent_count_channel])\n",
    "env.reset()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "behavior_specs = env.behavior_specs\n",
    "print(f\"Behaviour specs {behavior_specs}\")\n",
    "behavior_name = list(behavior_specs)[0]\n",
    "spec = env.behavior_specs[behavior_name]\n",
    "\n",
    "print(f\"Name of the behavior : {behavior_name}\")\n",
    "print(\"Number of observations : \", len(spec.observation_specs)) # vector if 1\n",
    "\n",
    "# Is the Action continuous or multi-discrete ?\n",
    "if spec.action_spec.continuous_size > 0:\n",
    "  print(f\"There are {spec.action_spec.continuous_size} continuous actions\")\n",
    "if spec.action_spec.is_discrete():\n",
    "  print(f\"There are {spec.action_spec.discrete_size} discrete actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def create_folder(file_name_prefix):\n",
    "    directory = os.path.dirname(f\"{file_name_prefix}\")\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def set_agents_and_double_reset(num_agents: int):\n",
    "    agent_count_channel.send_int(data=num_agents) \n",
    "    env.reset()\n",
    "    env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_observation_for_agent(agent: int, observations):\n",
    "    for observation in observations:\n",
    "        key = int(observation.split(\"=\")[2])\n",
    "        if key == agent:\n",
    "            return observations[observation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def map_agent_ids(decision_steps):\n",
    "    \"\"\"\n",
    "    Map agent ids between NEAT and UNITY.\n",
    "\n",
    "    Args:\n",
    "        decision_steps: An iterable containing decision steps.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of two dictionaries: (unity_to_neat_map, neat_to_unity_map)\n",
    "    \"\"\"\n",
    "    unity_to_neat_map = {}\n",
    "    neat_to_unity_map = {}\n",
    "    id_count = 0\n",
    "    for step in decision_steps:\n",
    "        unity_to_neat_map[step] = id_count\n",
    "        neat_to_unity_map[id_count] = step\n",
    "        id_count += 1\n",
    "    return unity_to_neat_map, neat_to_unity_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def create_policies(genomes, cfg):\n",
    "    policies = []\n",
    "    for _, g in genomes:\n",
    "        g.fitness = 0\n",
    "        policy = neat.nn.RecurrentNetwork.create(g, cfg)\n",
    "        policies.append(policy)\n",
    "    return policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, cfg):\n",
    "    global generation \n",
    "    generation += 1\n",
    "    num_runs = 3\n",
    "\n",
    "    policies = create_policies(genomes, cfg)\n",
    "    set_agents_and_double_reset(len(policies))\n",
    "    decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "    agent_count = len(decision_steps.agent_id)\n",
    "\n",
    "    unity_to_neat_map, neat_to_unity_map = map_agent_ids(decision_steps)\n",
    "\n",
    "\n",
    "\n",
    "    episode_rewards = [0] * agent_count\n",
    "    print(f\"Agent count: {agent_count}\")\n",
    "    for _ in range(num_runs):\n",
    "        env.reset()\n",
    "        decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "        done = False  # Vectorized initialization\n",
    "        removed_agents = []\n",
    "        while not done:\n",
    "            for agent in decision_steps:\n",
    "                if unity_to_neat_map[agent] not in removed_agents:\n",
    "                    nn_input =  np.asarray(decision_steps[agent].obs[:])\n",
    "                    #print(f\"NN INPUT: {nn_input}, agent: {agent}\")\n",
    "                    #print(f\"NN INPUT[0]: {nn_input[0]}, agent: {agent}\")\n",
    "                    actions = policies[unity_to_neat_map[agent]].activate(nn_input[0])\n",
    "                    #print(f\"NN OUTPUT: {actions}, agent: {agent}\")\n",
    "                    continous_actions = np.asarray([actions])\n",
    "                    continous_actions = np.clip(continous_actions, -1, 1)\n",
    "                    action_tuple = ActionTuple(discrete=None, continuous=continous_actions)\n",
    "                    env.set_action_for_agent(behavior_name=behavior_name, \n",
    "                                            agent_id=agent, \n",
    "                                            action=action_tuple)\n",
    "            env.step()\n",
    "            decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "            for agent in range(agent_count):\n",
    "                if agent not in removed_agents:\n",
    "                    local_agent = neat_to_unity_map[agent]\n",
    "                    if local_agent in terminal_steps:\n",
    "                        episode_rewards[agent] += terminal_steps[local_agent].reward\n",
    "                        removed_agents.append(agent)\n",
    "                        #print(f\"Finished: {agent}\")\n",
    "                    elif local_agent in decision_steps:\n",
    "                        episode_rewards[agent] += decision_steps[local_agent].reward\n",
    "            if len(removed_agents) >= agent_count:\n",
    "                done = True\n",
    "    for i, (_, genome) in enumerate(genomes):\n",
    "        genome.fitness = episode_rewards[i] / num_runs\n",
    "    if generation % SAVE_INTERVAL == 0:\n",
    "      global file_name_prefix\n",
    "      best_genome_current_generation = max(genomes, key=lambda x: x[1].fitness) \n",
    "      with open(file_name_prefix+'best-'+str(generation)+'.pkl', 'wb') as f:\n",
    "          pickle.dump(best_genome_current_generation, f)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def run(config_file, run, datte):\n",
    "    print(f\"Running {run}\")\n",
    "    global file_name_prefix\n",
    "    file_name_prefix = f\"wind-env/checkpoints/{datte}/run-{run}/\"\n",
    "    create_folder(file_name_prefix=file_name_prefix)\n",
    "\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_file)\n",
    "    \n",
    "    pop = neat.Population(config)\n",
    "\n",
    "    stats = neat.StatisticsReporter()\n",
    "\n",
    "    pop.add_reporter(stats)\n",
    "    pop.add_reporter(neat.TBReporter(True, 0, run, datte))\n",
    "    #pop.add_reporter(neat.StdOutReporter(True))\n",
    "    best = pop.run(eval_genomes, MAX_GENS)\n",
    "    # Display the winning genome.\n",
    "    # print('\\nBest genome:\\n{!s}'.format(best))\n",
    "    print(\"Finished running!\")\n",
    "    \n",
    "    # Save best genome\n",
    "    with open(f'logs/{datte}/{run}/best.pkl', 'wb') as f:\n",
    "        pickle.dump(best, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "config_path = '../configs/config-recurrent-wind'\n",
    "datte = datetime.datetime.now().strftime(\"%d-%m-%Y--%H_%M\")\n",
    "# pre create folders for checkpointer\n",
    "for r in range(NUM_RUNS):\n",
    "    run(config_path, r, datte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualize\n",
    "import pickle\n",
    "import neat\n",
    "save_nn_destination = '../co.pkl'\n",
    "config_path = '../configs/config-recurrent-forest'\n",
    "\n",
    "with open(save_nn_destination, \"rb\") as f:\n",
    "    genome = pickle.load(f)\n",
    "    genome = genome[1]\n",
    "    print('\\nBest genome:\\n{!s}'.format(genome))\n",
    "\n",
    "with open(save_nn_destination, 'wb') as f:\n",
    "    pickle.dump(best, f)\n",
    "print(genome.fitness)\n",
    "config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                    neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                    config_path)\n",
    "visualize.draw_net(config, genome, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
