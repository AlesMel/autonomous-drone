{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import neat\n",
    "import datetime\n",
    "import os\n",
    "import math\n",
    "\n",
    "from comunication_channel import AgentLogChannel\n",
    "\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from mlagents_envs.base_env import ActionTuple\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "NUM_RUNS = 5\n",
    "MAX_GENS = 5000\n",
    "\n",
    "generation = 0\n",
    "SAVE_INTERVAL = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "engine_config_channel = EngineConfigurationChannel()\n",
    "engine_config_channel.set_configuration_parameters(time_scale=4)\n",
    "agent_count_channel = AgentLogChannel()\n",
    "\n",
    "env_path = \"../Builds/train-env/autonomous-drone.exe\"\n",
    "save_nn_destination = '../result/best.pkl'\n",
    "\n",
    "env = UnityEnvironment(file_name=None, worker_id=0, no_graphics=True, side_channels=[engine_config_channel, agent_count_channel])\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behaviour specs <mlagents_envs.base_env.BehaviorMapping object at 0x00000253A9089690>\n",
      "Name of the behavior : ForestControl?team=0\n",
      "Number of observations :  1\n",
      "There are 4 continuous actions\n"
     ]
    }
   ],
   "source": [
    "behavior_specs = env.behavior_specs\n",
    "print(f\"Behaviour specs {behavior_specs}\")\n",
    "behavior_name = list(behavior_specs)[0]\n",
    "spec = env.behavior_specs[behavior_name]\n",
    "\n",
    "print(f\"Name of the behavior : {behavior_name}\")\n",
    "print(\"Number of observations : \", len(spec.observation_specs)) # vector if 1\n",
    "\n",
    "# Is the Action continuous or multi-discrete ?\n",
    "if spec.action_spec.continuous_size > 0:\n",
    "  print(f\"There are {spec.action_spec.continuous_size} continuous actions\")\n",
    "if spec.action_spec.is_discrete():\n",
    "  print(f\"There are {spec.action_spec.discrete_size} discrete actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def create_folder(file_name_prefix):\n",
    "    directory = os.path.dirname(f\"{file_name_prefix}\")\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def set_agents_and_double_reset(num_agents: int):\n",
    "    agent_count_channel.send_int(data=num_agents) \n",
    "    env.reset()\n",
    "    env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_observation_for_agent(agent: int, observations):\n",
    "    for observation in observations:\n",
    "        key = int(observation.split(\"=\")[2])\n",
    "        if key == agent:\n",
    "            return observations[observation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def map_agent_ids(decision_steps):\n",
    "    \"\"\"\n",
    "    Map agent ids between NEAT and UNITY.\n",
    "\n",
    "    Args:\n",
    "        decision_steps: An iterable containing decision steps.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of two dictionaries: (unity_to_neat_map, neat_to_unity_map)\n",
    "    \"\"\"\n",
    "    unity_to_neat_map = {}\n",
    "    neat_to_unity_map = {}\n",
    "    id_count = 0\n",
    "    for step in decision_steps:\n",
    "        unity_to_neat_map[step] = id_count\n",
    "        neat_to_unity_map[id_count] = step\n",
    "        id_count += 1\n",
    "    return unity_to_neat_map, neat_to_unity_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def create_policies(genomes, cfg):\n",
    "    policies = []\n",
    "    for _, g in genomes:\n",
    "        g.fitness = 0\n",
    "        policy = neat.nn.RecurrentNetwork.create(g, cfg)\n",
    "        policies.append(policy)\n",
    "    return policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, cfg):\n",
    "    global generation \n",
    "    generation += 1\n",
    "\n",
    "    policies = create_policies(genomes, cfg)\n",
    "    set_agents_and_double_reset(len(policies))\n",
    "    decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "    agent_count = len(decision_steps.agent_id)\n",
    "\n",
    "    unity_to_neat_map, neat_to_unity_map = map_agent_ids(decision_steps)\n",
    "\n",
    "    done = False  # Vectorized initialization\n",
    "    removed_agents = []\n",
    "\n",
    "    episode_rewards = [0] * agent_count\n",
    "    print(f\"Agent count: {agent_count}\")\n",
    "\n",
    "    while not done:\n",
    "        for agent in decision_steps:\n",
    "            if unity_to_neat_map[agent] not in removed_agents:\n",
    "                obs = np.concatenate(decision_steps[agent].obs[:])\n",
    "                nn_input =  np.asarray(obs)\n",
    "                #print(f\"NN INPUT: {nn_input}, agent: {agent}\")\n",
    "                #print(f\"NN INPUT[0]: {nn_input[0]}, agent: {agent}\")\n",
    "                actions = policies[unity_to_neat_map[agent]].activate(nn_input)\n",
    "                # print(f\"NN OUTPUT: {actions}, agent: {agent}\")\n",
    "                continous_actions = np.asarray([actions])\n",
    "                # continous_actions = np.clip(continous_actions, -1, 1)\n",
    "                action_tuple = ActionTuple(discrete=None, continuous=continous_actions)\n",
    "                env.set_action_for_agent(behavior_name=behavior_name, \n",
    "                                        agent_id=agent, \n",
    "                                        action=action_tuple)\n",
    "        env.step()\n",
    "        decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "        for agent in range(agent_count):\n",
    "            if agent not in removed_agents:\n",
    "                local_agent = neat_to_unity_map[agent]\n",
    "                if local_agent in terminal_steps:\n",
    "                    episode_rewards[agent] += terminal_steps[local_agent].reward\n",
    "                    removed_agents.append(agent)\n",
    "                    #print(f\"Finished: {agent}\")\n",
    "                elif local_agent in decision_steps:\n",
    "                    episode_rewards[agent] += decision_steps[local_agent].reward\n",
    "                 \n",
    "\n",
    "        if len(removed_agents) >= agent_count:\n",
    "            done = True\n",
    "    for i, (_, genome) in enumerate(genomes):\n",
    "        # print(episode_rewards[i])\n",
    "        genome.fitness = episode_rewards[i]\n",
    "    if generation % SAVE_INTERVAL == 0:\n",
    "      global file_name_prefix\n",
    "      best_genome_current_generation = max(genomes, key=lambda x: x[1].fitness) \n",
    "      with open(file_name_prefix+'best-'+str(generation)+'.pkl', 'wb') as f:\n",
    "          pickle.dump(best_genome_current_generation, f)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def run(config_file, run, datte):\n",
    "    print(f\"Running {run}\")\n",
    "    global file_name_prefix\n",
    "    file_name_prefix = f\"forest-env/checkpoints/{datte}/run-{run}/\"\n",
    "    create_folder(file_name_prefix=file_name_prefix)\n",
    "\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_file)\n",
    "    \n",
    "    pop = neat.Population(config)\n",
    "\n",
    "    stats = neat.StatisticsReporter()\n",
    "\n",
    "    pop.add_reporter(stats)\n",
    "    pop.add_reporter(neat.TBReporter(True, 0, run, datte))\n",
    "    #pop.add_reporter(neat.StdOutReporter(True))\n",
    "    best = pop.run(eval_genomes, MAX_GENS)\n",
    "    # Display the winning genome.\n",
    "    # print('\\nBest genome:\\n{!s}'.format(best))\n",
    "    print(\"Finished running!\")\n",
    "    \n",
    "    # Save best genome\n",
    "    with open(f'logs/{datte}/{run}/best.pkl', 'wb') as f:\n",
    "        pickle.dump(best, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 0\n",
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n",
      "Agent count: 50\n",
      "Population's average fitness: -0.99664 stdev: 0.01749\n",
      "Best fitness: -0.87707 - size: (8, 288) - species 1 - id 17\n",
      "Best fitness ever found! : -0.8770699256565422\n",
      "Population of 50 members in 1 species:\n",
      "   ID   age  size   fitness   adj fit  stag\n",
      "  ====  ===  ====  =========  =======  ====\n",
      "     1    0    50  -0.8770699256565422  0.0033616033366428155     0\n",
      "Total extinctions: 0\n",
      "Generation time: 5.573 sec\n",
      "\n",
      " ****** Running generation 1 ****** \n",
      "\n",
      "Agent count: 50\n",
      "Population's average fitness: -0.99099 stdev: 0.03011\n",
      "Best fitness: -0.85128 - size: (7, 216) - species 1 - id 86\n",
      "Best fitness ever found! : -0.8512824179117615\n",
      "Population of 50 members in 1 species:\n",
      "   ID   age  size   fitness   adj fit  stag\n",
      "  ====  ===  ====  =========  =======  ====\n",
      "     1    1    50  -0.8512824179117615  0.009014562928798764     0\n",
      "Total extinctions: 0\n",
      "Generation time: 2.691 sec (4.132 average)\n",
      "\n",
      " ****** Running generation 2 ****** \n",
      "\n",
      "Agent count: 50\n",
      "Population's average fitness: -0.99086 stdev: 0.03404\n",
      "Best fitness: -0.84442 - size: (8, 215) - species 1 - id 123\n",
      "Best fitness ever found! : -0.8444160456472584\n",
      "Population of 50 members in 1 species:\n",
      "   ID   age  size   fitness   adj fit  stag\n",
      "  ====  ===  ====  =========  =======  ====\n",
      "     1    2    50  -0.8444160456472584  0.009139435807972274     0\n",
      "Total extinctions: 0\n",
      "Generation time: 3.040 sec (3.768 average)\n",
      "\n",
      " ****** Running generation 3 ****** \n",
      "\n",
      "Agent count: 50\n",
      "Population's average fitness: -0.99285 stdev: 0.02972\n",
      "Best fitness: -0.84442 - size: (8, 215) - species 1 - id 123\n",
      "Population of 50 members in 1 species:\n",
      "   ID   age  size   fitness   adj fit  stag\n",
      "  ====  ===  ====  =========  =======  ====\n",
      "     1    3    50  -0.8444160456472584  0.007152417042197934     1\n",
      "Total extinctions: 0\n",
      "Generation time: 2.693 sec (3.499 average)\n",
      "\n",
      " ****** Running generation 4 ****** \n",
      "\n",
      "Agent count: 50\n"
     ]
    }
   ],
   "source": [
    "config_path = '../configs/config-recurrent-forest'\n",
    "datte = datetime.datetime.now().strftime(\"%d-%m-%Y--%H_%M\")\n",
    "# pre create folders                                                    for checkpointer\n",
    "for r in range(NUM_RUNS):\n",
    "    run(config_path, r, datte)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualize\n",
    "import pickle\n",
    "import neat\n",
    "save_nn_destination = '../result/best.pkl'\n",
    "config_path = '../configs/config-recurrent-forest'\n",
    "\n",
    "with open(save_nn_destination, \"rb\") as f:\n",
    "    genome = pickle.load(f)\n",
    "    genome = genome[1]\n",
    "    print('\\nBest genome:\\n{!s}'.format(genome))\n",
    "print(genome.fitness)\n",
    "config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                    neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                    config_path)\n",
    "visualize.draw_net(config, genome, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
