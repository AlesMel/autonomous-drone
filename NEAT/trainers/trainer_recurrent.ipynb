{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import neat\n",
    "import datetime\n",
    "import os\n",
    "import math\n",
    "\n",
    "from comunication_channel import AgentLogChannel\n",
    "\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from mlagents_envs.base_env import ActionTuple\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "NUM_RUNS = 1\n",
    "MAX_GENS = 3000\n",
    "\n",
    "generation = 0\n",
    "SAVE_INTERVAL = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "engine_config_channel = EngineConfigurationChannel()\n",
    "engine_config_channel.set_configuration_parameters(time_scale=1)\n",
    "agent_count_channel = AgentLogChannel()\n",
    "\n",
    "env_path = \"../Builds/train-env/autonomous-drone.exe\"\n",
    "save_nn_destination = '../result/best.pkl'\n",
    "\n",
    "env = UnityEnvironment(file_name=None, worker_id=0, no_graphics=False, side_channels=[engine_config_channel, agent_count_channel])\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behaviour specs <mlagents_envs.base_env.BehaviorMapping object at 0x0000023A6C581120>\n",
      "Name of the behavior : DroneControl?team=0\n",
      "Number of observations :  1\n",
      "There are 4 continuous actions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "behavior_specs = env.behavior_specs\n",
    "print(f\"Behaviour specs {behavior_specs}\")\n",
    "behavior_name = list(behavior_specs)[0]\n",
    "spec = env.behavior_specs[behavior_name]\n",
    "\n",
    "print(f\"Name of the behavior : {behavior_name}\")\n",
    "print(\"Number of observations : \", len(spec.observation_specs)) # vector if 1\n",
    "\n",
    "# Is the Action continuous or multi-discrete ?\n",
    "if spec.action_spec.continuous_size > 0:\n",
    "  print(f\"There are {spec.action_spec.continuous_size} continuous actions\")\n",
    "if spec.action_spec.is_discrete():\n",
    "  print(f\"There are {spec.action_spec.discrete_size} discrete actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def create_folder(file_name_prefix):\n",
    "    directory = os.path.dirname(f\"{file_name_prefix}\")\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def set_agents_and_double_reset(num_agents: int):\n",
    "    agent_count_channel.send_int(data=num_agents) \n",
    "    env.reset()\n",
    "    env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_observation_for_agent(agent: int, observations):\n",
    "    for observation in observations:\n",
    "        key = int(observation.split(\"=\")[2])\n",
    "        if key == agent:\n",
    "            return observations[observation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def map_agent_ids(decision_steps):\n",
    "    \"\"\"\n",
    "    Map agent ids between NEAT and UNITY.\n",
    "\n",
    "    Args:\n",
    "        decision_steps: An iterable containing decision steps.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of two dictionaries: (unity_to_neat_map, neat_to_unity_map)\n",
    "    \"\"\"\n",
    "    unity_to_neat_map = {}\n",
    "    neat_to_unity_map = {}\n",
    "    id_count = 0\n",
    "    for step in decision_steps:\n",
    "        unity_to_neat_map[step] = id_count\n",
    "        neat_to_unity_map[id_count] = step\n",
    "        id_count += 1\n",
    "    return unity_to_neat_map, neat_to_unity_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def create_policies(genomes, cfg):\n",
    "    policies = []\n",
    "    for _, g in genomes:\n",
    "        g.fitness = 0\n",
    "        policy = neat.nn.RecurrentNetwork.create(g, cfg)\n",
    "        policies.append(policy)\n",
    "    return policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, cfg):\n",
    "    global generation \n",
    "    generation += 1\n",
    "\n",
    "    policies = create_policies(genomes, cfg)\n",
    "    set_agents_and_double_reset(len(policies))\n",
    "    decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "    agent_count = len(decision_steps.agent_id)\n",
    "\n",
    "    unity_to_neat_map, neat_to_unity_map = map_agent_ids(decision_steps)\n",
    "\n",
    "    done = False  # Vectorized initialization\n",
    "    removed_agents = []\n",
    "\n",
    "    episode_rewards = [0] * agent_count\n",
    "    print(f\"Agent count: {agent_count}\")\n",
    "\n",
    "    while not done:\n",
    "        for agent in decision_steps:\n",
    "            if unity_to_neat_map[agent] not in removed_agents:\n",
    "                nn_input =  np.asarray(decision_steps[agent].obs[:])\n",
    "                #print(f\"NN INPUT: {nn_input}, agent: {agent}\")\n",
    "                #print(f\"NN INPUT[0]: {nn_input[0]}, agent: {agent}\")\n",
    "                actions = policies[unity_to_neat_map[agent]].activate(nn_input[0])\n",
    "                print(f\"NN OUTPUT: {actions}, agent: {agent}\")\n",
    "                continous_actions = np.asarray([actions])\n",
    "                # continous_actions = np.clip(continous_actions, -1, 1)\n",
    "                action_tuple = ActionTuple(discrete=None, continuous=continous_actions)\n",
    "                env.set_action_for_agent(behavior_name=behavior_name, \n",
    "                                        agent_id=agent, \n",
    "                                        action=action_tuple)\n",
    "        env.step()\n",
    "        decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "        for agent in range(agent_count):\n",
    "            if agent not in removed_agents:\n",
    "                local_agent = neat_to_unity_map[agent]\n",
    "                if local_agent in terminal_steps:\n",
    "                    episode_rewards[agent] += terminal_steps[local_agent].reward\n",
    "                    removed_agents.append(agent)\n",
    "                    #print(f\"Finished: {agent}\")\n",
    "                elif local_agent in decision_steps:\n",
    "                    episode_rewards[agent] += decision_steps[local_agent].reward\n",
    "                 \n",
    "\n",
    "        if len(removed_agents) >= agent_count:\n",
    "            done = True\n",
    "    for i, (_, genome) in enumerate(genomes):\n",
    "        genome.fitness = episode_rewards[i]\n",
    "    if generation % SAVE_INTERVAL == 0:\n",
    "      global file_name_prefix\n",
    "      best_genome_current_generation = max(genomes, key=lambda x: x[1].fitness) \n",
    "      with open(file_name_prefix+'best-'+str(generation)+'.pkl', 'wb') as f:\n",
    "          pickle.dump(best_genome_current_generation, f)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def run(config_file, run, datte):\n",
    "    print(f\"Running {run}\")\n",
    "    global file_name_prefix\n",
    "    file_name_prefix = f\"../checkpoints/{datte}/run-{run}/\"\n",
    "    create_folder(file_name_prefix=file_name_prefix)\n",
    "\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_file)\n",
    "    \n",
    "    pop = neat.Population(config)\n",
    "\n",
    "    stats = neat.StatisticsReporter()\n",
    "\n",
    "    pop.add_reporter(stats)\n",
    "    pop.add_reporter(neat.TBReporter(True, 0, run, datte))\n",
    "    #pop.add_reporter(neat.StdOutReporter(True))\n",
    "    best = pop.run(eval_genomes, MAX_GENS)\n",
    "    # Display the winning genome.\n",
    "    # print('\\nBest genome:\\n{!s}'.format(best))\n",
    "    print(\"Finished running!\")\n",
    "    \n",
    "    # Save best genome\n",
    "    with open(f'logs/{datte}/{run}/best.pkl', 'wb') as f:\n",
    "        pickle.dump(best, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 0\n",
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n",
      "Agent count: 50\n"
     ]
    },
    {
     "ename": "UnityCommunicatorStoppedException",
     "evalue": "Communicator has exited.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnityCommunicatorStoppedException\u001b[0m         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# pre create folders for checkpointer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_RUNS):\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatte\u001b[49m\u001b[43m)\u001b[49m                      \n",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(config_file, run, datte)\u001b[0m\n\u001b[0;32m     16\u001b[0m pop\u001b[38;5;241m.\u001b[39madd_reporter(neat\u001b[38;5;241m.\u001b[39mTBReporter(\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m0\u001b[39m, run, datte))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#pop.add_reporter(neat.StdOutReporter(True))\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mpop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_genomes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_GENS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Display the winning genome.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# print('\\nBest genome:\\n{!s}'.format(best))\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished running!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\alesm\\documents\\neat-python-plus\\neat\\population.py:88\u001b[0m, in \u001b[0;36mPopulation.run\u001b[1;34m(self, fitness_function, n)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreporters\u001b[38;5;241m.\u001b[39mstart_generation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Evaluate all genomes using the user-provided function.\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m \u001b[43mfitness_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Gather and report statistics.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m, in \u001b[0;36meval_genomes\u001b[1;34m(genomes, cfg)\u001b[0m\n\u001b[0;32m     28\u001b[0m         action_tuple \u001b[38;5;241m=\u001b[39m ActionTuple(discrete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, continuous\u001b[38;5;241m=\u001b[39mcontinous_actions)\n\u001b[0;32m     29\u001b[0m         env\u001b[38;5;241m.\u001b[39mset_action_for_agent(behavior_name\u001b[38;5;241m=\u001b[39mbehavior_name, \n\u001b[0;32m     30\u001b[0m                                 agent_id\u001b[38;5;241m=\u001b[39magent, \n\u001b[0;32m     31\u001b[0m                                 action\u001b[38;5;241m=\u001b[39maction_tuple)\n\u001b[1;32m---> 32\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m decision_steps, terminal_steps \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mget_steps(behavior_name)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(agent_count):\n",
      "File \u001b[1;32mc:\\Users\\alesm\\miniconda3\\envs\\mlagents\\lib\\site-packages\\mlagents_envs\\timers.py:305\u001b[0m, in \u001b[0;36mtimed.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hierarchical_timer(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m):\n\u001b[1;32m--> 305\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alesm\\miniconda3\\envs\\mlagents\\lib\\site-packages\\mlagents_envs\\environment.py:350\u001b[0m, in \u001b[0;36mUnityEnvironment.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    348\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_communicator\u001b[38;5;241m.\u001b[39mexchange(step_input, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll_process)\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnityCommunicatorStoppedException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommunicator has exited.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_behavior_specs(outputs)\n\u001b[0;32m    352\u001b[0m rl_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mrl_output\n",
      "\u001b[1;31mUnityCommunicatorStoppedException\u001b[0m: Communicator has exited."
     ]
    }
   ],
   "source": [
    "config_path = '../configs/config-recurrent'\n",
    "datte = datetime.datetime.now().strftime(\"%d-%m-%Y--%H_%M\")\n",
    "# pre create folders for checkpointer\n",
    "for r in range(NUM_RUNS):\n",
    "    run(config_path, r, datte)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
