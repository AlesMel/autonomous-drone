{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import neat\n",
    "import os\n",
    "import keyboard\n",
    "\n",
    "#from game_config import game_config\n",
    "# MLAGENTS stuff\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from mlagents_envs.base_env import ActionTuple\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "engine_config_channel = EngineConfigurationChannel()\n",
    "from comunication_channel import AgentLogChannel\n",
    "agent_count_channel = AgentLogChannel()\n",
    "engine_config_channel.set_configuration_parameters(time_scale=1)\n",
    "\n",
    "env_path = \"../Builds/train-env/autonomous-drone.exe\"\n",
    "\n",
    "env = UnityEnvironment(file_name=None, seed=0, no_graphics=False, side_channels=[engine_config_channel, agent_count_channel])\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behaviour specs <mlagents_envs.base_env.BehaviorMapping object at 0x00000270F49C6D70>\n",
      "Name of the behavior : WindControl?team=0\n",
      "Number of observations :  1\n"
     ]
    }
   ],
   "source": [
    "behavior_specs = env.behavior_specs\n",
    "print(f\"Behaviour specs {behavior_specs}\")\n",
    "behavior_name = list(behavior_specs)[0]\n",
    "spec = env.behavior_specs[behavior_name]\n",
    "\n",
    "print(f\"Name of the behavior : {behavior_name}\")\n",
    "print(\"Number of observations : \", len(spec.observation_specs)) # vector if 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 continuous actions\n"
     ]
    }
   ],
   "source": [
    "# Is the Action continuous or multi-discrete ?\n",
    "if spec.action_spec.continuous_size > 0:\n",
    "  print(f\"There are {spec.action_spec.continuous_size} continuous actions\")\n",
    "if spec.action_spec.is_discrete():\n",
    "  print(f\"There are {spec.action_spec.discrete_size} discrete actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def map_agent_ids(decision_steps):\n",
    "    \"\"\"\n",
    "    Map agent ids between NEAT and UNITY.\n",
    "\n",
    "    Args:\n",
    "        decision_steps: An iterable containing decision steps.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of two dictionaries: (unity_to_neat_map, neat_to_unity_map)\n",
    "    \"\"\"\n",
    "    unity_to_neat_map = {}\n",
    "    neat_to_unity_map = {}\n",
    "    id_count = 0\n",
    "    for step in decision_steps:\n",
    "        unity_to_neat_map[step] = id_count\n",
    "        neat_to_unity_map[id_count] = step\n",
    "        id_count += 1\n",
    "    return unity_to_neat_map, neat_to_unity_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def set_agents_and_double_reset(num_agents: int):\n",
    "    agent_count_channel.send_int(data=num_agents) \n",
    "    env.reset()\n",
    "    env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "set_agents_and_double_reset(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "def eval_agent(genome, cfg):\n",
    "    i = 0\n",
    "    send_array = [2, 1, 2]\n",
    "\n",
    "    while True:\n",
    "        #policy = neat.ctrnn.CTRNN.create(genome, cfg, 0.02)\n",
    "        policy = neat.nn.RecurrentNetwork.create(genome, cfg)\n",
    "        set_agents_and_double_reset(random.randint(1, 1))\n",
    "        decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "        agent_count = len(decision_steps.agent_id)\n",
    "        policies = [policy] * agent_count\n",
    "\n",
    "        unity_to_neat_map, neat_to_unity_map = map_agent_ids(decision_steps)\n",
    "\n",
    "        done = False  # Vectorized initialization\n",
    "        removed_agents = []\n",
    "\n",
    "        episode_rewards = [0] * agent_count\n",
    "        print(f\"Agent count: {agent_count}\")\n",
    "        while not done:\n",
    "            # if keyboard.is_pressed('q'):  # Check if 'q' is pressed\n",
    "            #     env.close()\n",
    "            #     return\n",
    "            for agent in decision_steps:\n",
    "                if unity_to_neat_map[agent] not in removed_agents:\n",
    "                    nn_input = np.asarray(decision_steps[agent].obs[:])\n",
    "                    #print(f\"{agent} {nn_input}\")\n",
    "                    actions = policies[unity_to_neat_map[agent]].activate(nn_input[0])\n",
    "                    #print(f\"{agent} {actions}\")\n",
    "                    #actions = [0, 0.5,0.5, 1]\n",
    "                    continous_actions = np.asarray([actions])\n",
    "                    continous_actions = np.clip(continous_actions, -1, 1)\n",
    "\n",
    "                    action_tuple = ActionTuple(discrete=None, continuous=continous_actions)\n",
    "                    env.set_action_for_agent(behavior_name=behavior_name, \n",
    "                                            agent_id=agent, \n",
    "                                            action=action_tuple)\n",
    "            env.step()\n",
    "            decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "            for agent in range(agent_count):\n",
    "                if agent not in removed_agents:\n",
    "                    local_agent = neat_to_unity_map[agent]\n",
    "                    if local_agent in terminal_steps:\n",
    "                        episode_rewards[agent] += terminal_steps[local_agent].reward\n",
    "                        removed_agents.append(agent)\n",
    "                    elif local_agent in decision_steps:\n",
    "                        episode_rewards[agent] += decision_steps[local_agent].reward                             \n",
    "            if len(removed_agents) >= agent_count:\n",
    "                print(\".\") \n",
    "                done = True\n",
    "        for reward in episode_rewards:\n",
    "            print(reward)\n",
    "        #while keyboard.is_pressed('c') == False:\n",
    "        #    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 9057\n",
      "Fitness: 51.17962782316354\n",
      "Nodes:\n",
      "\t0 DefaultNodeGene(key=0, bias=0.015570083272938745, response=1.0, activation=clamped, aggregation=sum)\n",
      "\t1 DefaultNodeGene(key=1, bias=0.23292698012109525, response=1.0, activation=clamped, aggregation=sum)\n",
      "\t2 DefaultNodeGene(key=2, bias=0.035022534895158206, response=1.0, activation=clamped, aggregation=sum)\n",
      "\t3 DefaultNodeGene(key=3, bias=0.1409022761420273, response=1.0, activation=clamped, aggregation=sum)\n",
      "Connections:\n",
      "\tDefaultConnectionGene(key=(-9, 0), weight=-0.7703546474872193, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-8, 1), weight=-0.20100054938288375, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-8, 3), weight=-0.10037896524433304, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-7, 0), weight=0.33636660036493343, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-7, 1), weight=0.01576301967088703, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-7, 2), weight=-0.33316717983565663, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-7, 3), weight=-0.0701137269506181, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-6, 0), weight=0.189387810987668, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-6, 1), weight=0.0036280180988405904, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-6, 2), weight=-0.8871453846652362, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-6, 3), weight=1.4828666335710876, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-5, 0), weight=-0.014148950953660866, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-5, 1), weight=-0.2986046805271359, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-5, 2), weight=-0.17873758816519178, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-5, 3), weight=-0.5355864307154699, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-4, 0), weight=0.23678519322553665, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-4, 1), weight=-0.2396721091829278, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-4, 2), weight=-0.8317430354329003, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-4, 3), weight=-0.3098015887817653, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-3, 0), weight=0.24336639889971398, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-3, 1), weight=-0.07090401640364624, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-3, 2), weight=-1.4095053222195928, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-3, 3), weight=-0.6715801468856486, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 2), weight=-1.383136963082551, enabled=True)\n",
      "\tDefaultConnectionGene(key=(-2, 3), weight=0.4163336167380395, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-1, 1), weight=0.04792439695631343, enabled=False)\n",
      "\tDefaultConnectionGene(key=(-1, 3), weight=0.6063763571146767, enabled=False)\n",
      "\tDefaultConnectionGene(key=(0, 0), weight=0.4845260818053278, enabled=True)\n",
      "\tDefaultConnectionGene(key=(2, 2), weight=-0.90790533536888, enabled=False)\n",
      "\tDefaultConnectionGene(key=(3, 3), weight=0.06647160497147771, enabled=False)\n",
      "51.17962782316354\n",
      "Agent count: 1\n"
     ]
    }
   ],
   "source": [
    "save_nn_destination = '../result/best.pkl'\n",
    "\n",
    "with open(save_nn_destination, \"rb\") as f:\n",
    "    genome = pickle.load(f)\n",
    "    genome = genome[1]\n",
    "    print(genome)\n",
    "print(genome.fitness)\n",
    "config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                    neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                    '../configs/config-recurrent-wind')\n",
    "# Save best genome\n",
    "# with open(f'best.pkl', 'wb') as f:\n",
    "#    pickle.dump(genome, f)\n",
    "eval_agent(genome, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualize\n",
    "name = 'winner-{0}'.format(1)\n",
    "visualize.draw_net(config, genome, view=False, filename=name + \"-net.gv\")\n",
    "visualize.draw_net(config, genome, view=False, filename=name + \"-net-pruned.gv\", prune_unused=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
