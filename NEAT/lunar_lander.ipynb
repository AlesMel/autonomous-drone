{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from evotorch.decorators import pass_info\n",
    "\n",
    "\n",
    "# The decorator `@pass_info` used below tells the problem class `GymNE`\n",
    "# to pass information regarding the gym environment via keyword arguments\n",
    "# such as `obs_length` and `act_length`.\n",
    "@pass_info\n",
    "class LinearPolicy(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_length: int, # Number of observations from the environment\n",
    "        act_length: int, # Number of actions of the environment\n",
    "        bias: bool = True,  # Whether the policy should use biases\n",
    "        **kwargs # Anything else that is passed\n",
    "    ):\n",
    "        super().__init__()  # Always call super init for nn Modules\n",
    "        self.linear = nn.Linear(obs_length, act_length, bias = bias)\n",
    "        \n",
    "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
    "        # Forward pass of model simply applies linear layer to observations\n",
    "        return self.linear(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-13 10:37:51] INFO     <63928> evotorch.core: Instance of `GymNE` (id:2081106583440) -- The `dtype` for the problem's decision variables is set as torch.float32\n",
      "[2024-04-13 10:37:51] INFO     <63928> evotorch.core: Instance of `GymNE` (id:2081106583440) -- `eval_dtype` (the dtype of the fitnesses and evaluation data) is set as torch.float32\n",
      "[2024-04-13 10:37:51] INFO     <63928> evotorch.core: Instance of `GymNE` (id:2081106583440) -- The `device` of the problem is set as cpu\n",
      "[2024-04-13 10:37:51] INFO     <63928> evotorch.core: Instance of `GymNE` (id:2081106583440) -- The number of actors that will be allocated for parallelized evaluation is 4\n",
      "[2024-04-13 10:37:51] INFO     <63928> evotorch.core: Instance of `GymNE` (id:2081106583440) -- Number of GPUs that will be allocated per actor is None\n",
      "[2024-04-13 10:37:51] INFO     <63928> evotorch.core: Instance of `GymNE` (id:2081106583440) -- `eval_dtype` (the dtype of the fitnesses and evaluation data) is set as torch.float32\n",
      "[2024-04-13 10:37:51] INFO     <63928> evotorch.core: Instance of `GymNE` (id:2081106583440) -- The `device` of the problem is set as cpu\n",
      "[2024-04-13 10:37:51] INFO     <63928> evotorch.core: Instance of `GymNE` (id:2081106583440) -- The number of actors that will be allocated for parallelized evaluation is 4\n",
      "[2024-04-13 10:37:51] INFO     <63928> evotorch.core: Instance of `GymNE` (id:2081106583440) -- Number of GPUs that will be allocated per actor is None\n"
     ]
    }
   ],
   "source": [
    "problem = GymNE(\n",
    "    env=\"LunarLanderContinuous-v2\",\n",
    "    network=LinearPolicy,\n",
    "    network_args = {'bias': False},\n",
    "    num_actors= 4, \n",
    "    observation_normalization = False,\n",
    "    num_episodes = 3,\n",
    "    initial_bounds = (-0.3, 0.3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from evotorch.algorithms import Cosyne\n",
    "searcher = Cosyne(\n",
    "    problem,\n",
    "    num_elites = 1,\n",
    "    popsize=50,  \n",
    "    tournament_size = 4,\n",
    "    mutation_stdev = 0.3,\n",
    "    mutation_probability = 0.5,\n",
    "    permute_all = True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 10:38:14,132\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   iter : 1\n",
      "            median_eval : -140.58065795898438\n",
      "              mean_eval : -163.625\n",
      "          pop_best_eval : -34.220916748046875\n",
      "              best_eval : -34.220916748046875\n",
      "             worst_eval : -1476.3692626953125\n",
      "total_interaction_count : 38388\n",
      "    total_episode_count : 375\n",
      "\n",
      "                   iter : 2\n",
      "            median_eval : -133.28033447265625\n",
      "              mean_eval : -130.7618408203125\n",
      "          pop_best_eval : 20.381149291992188\n",
      "              best_eval : 20.381149291992188\n",
      "             worst_eval : -1476.3692626953125\n",
      "total_interaction_count : 61363\n",
      "    total_episode_count : 600\n",
      "\n",
      "                   iter : 3\n",
      "            median_eval : -131.8590850830078\n",
      "              mean_eval : -124.07872009277344\n",
      "          pop_best_eval : -10.64992618560791\n",
      "              best_eval : 20.381149291992188\n",
      "             worst_eval : -1476.3692626953125\n",
      "total_interaction_count : 82846\n",
      "    total_episode_count : 825\n",
      "\n",
      "                   iter : 4\n",
      "            median_eval : -134.85952758789062\n",
      "              mean_eval : -131.7218780517578\n",
      "          pop_best_eval : -20.407705307006836\n",
      "              best_eval : 20.381149291992188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 102958\n",
      "    total_episode_count : 1050\n",
      "\n",
      "                   iter : 5\n",
      "            median_eval : -123.36444854736328\n",
      "              mean_eval : -107.425537109375\n",
      "          pop_best_eval : -17.865671157836914\n",
      "              best_eval : 20.381149291992188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 123217\n",
      "    total_episode_count : 1275\n",
      "\n",
      "                   iter : 6\n",
      "            median_eval : -114.2401351928711\n",
      "              mean_eval : -99.8211898803711\n",
      "          pop_best_eval : 16.225584030151367\n",
      "              best_eval : 20.381149291992188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 144682\n",
      "    total_episode_count : 1500\n",
      "\n",
      "                   iter : 7\n",
      "            median_eval : -117.81182861328125\n",
      "              mean_eval : -97.64176940917969\n",
      "          pop_best_eval : 10.231133460998535\n",
      "              best_eval : 20.381149291992188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 167330\n",
      "    total_episode_count : 1725\n",
      "\n",
      "                   iter : 8\n",
      "            median_eval : -95.73081970214844\n",
      "              mean_eval : -75.59234619140625\n",
      "          pop_best_eval : 187.00485229492188\n",
      "              best_eval : 187.00485229492188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 192361\n",
      "    total_episode_count : 1950\n",
      "\n",
      "                   iter : 9\n",
      "            median_eval : -78.73328399658203\n",
      "              mean_eval : -73.68344116210938\n",
      "          pop_best_eval : 47.933345794677734\n",
      "              best_eval : 187.00485229492188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 218663\n",
      "    total_episode_count : 2175\n",
      "\n",
      "                   iter : 10\n",
      "            median_eval : -59.944339752197266\n",
      "              mean_eval : -52.103939056396484\n",
      "          pop_best_eval : 123.23876953125\n",
      "              best_eval : 187.00485229492188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 246938\n",
      "    total_episode_count : 2400\n",
      "\n",
      "                   iter : 11\n",
      "            median_eval : -36.75514602661133\n",
      "              mean_eval : -33.021297454833984\n",
      "          pop_best_eval : 158.80189514160156\n",
      "              best_eval : 187.00485229492188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 285867\n",
      "    total_episode_count : 2625\n",
      "\n",
      "                   iter : 12\n",
      "            median_eval : -30.46954917907715\n",
      "              mean_eval : -16.650175094604492\n",
      "          pop_best_eval : 179.07447814941406\n",
      "              best_eval : 187.00485229492188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 332772\n",
      "    total_episode_count : 2850\n",
      "\n",
      "                   iter : 13\n",
      "            median_eval : -20.089527130126953\n",
      "              mean_eval : -8.0413236618042\n",
      "          pop_best_eval : 182.0362548828125\n",
      "              best_eval : 187.00485229492188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 384351\n",
      "    total_episode_count : 3075\n",
      "\n",
      "                   iter : 14\n",
      "            median_eval : 16.666006088256836\n",
      "              mean_eval : 37.39232635498047\n",
      "          pop_best_eval : 250.90377807617188\n",
      "              best_eval : 250.90377807617188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 438055\n",
      "    total_episode_count : 3300\n",
      "\n",
      "                   iter : 15\n",
      "            median_eval : 12.676281929016113\n",
      "              mean_eval : 34.24266815185547\n",
      "          pop_best_eval : 206.42344665527344\n",
      "              best_eval : 250.90377807617188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 495817\n",
      "    total_episode_count : 3525\n",
      "\n",
      "                   iter : 16\n",
      "            median_eval : 4.433211803436279\n",
      "              mean_eval : 26.251632690429688\n",
      "          pop_best_eval : 234.35617065429688\n",
      "              best_eval : 250.90377807617188\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 553306\n",
      "    total_episode_count : 3750\n",
      "\n",
      "                   iter : 17\n",
      "            median_eval : 17.22222137451172\n",
      "              mean_eval : 54.58024978637695\n",
      "          pop_best_eval : 252.08294677734375\n",
      "              best_eval : 252.08294677734375\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 626826\n",
      "    total_episode_count : 3975\n",
      "\n",
      "                   iter : 18\n",
      "            median_eval : 65.11224365234375\n",
      "              mean_eval : 69.90220642089844\n",
      "          pop_best_eval : 247.04429626464844\n",
      "              best_eval : 252.08294677734375\n",
      "             worst_eval : -1876.5538330078125\n",
      "total_interaction_count : 700721\n",
      "    total_episode_count : 4200\n",
      "\n",
      "                   iter : 19\n",
      "            median_eval : 23.080936431884766\n",
      "              mean_eval : 48.948585510253906\n",
      "          pop_best_eval : 259.898193359375\n",
      "              best_eval : 259.898193359375\n",
      "             worst_eval : -5282.7919921875\n",
      "total_interaction_count : 781258\n",
      "    total_episode_count : 4425\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevotorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StdOutLogger\n\u001b[0;32m      3\u001b[0m StdOutLogger(searcher)\n\u001b[1;32m----> 4\u001b[0m \u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alesm\\miniconda3\\envs\\mlagents\\lib\\site-packages\\evotorch\\algorithms\\searchalgorithm.py:425\u001b[0m, in \u001b[0;36mSearchAlgorithm.run\u001b[1;34m(self, num_generations, reset_first_step_datetime)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_first_step_datetime()\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(num_generations)):\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end_of_run_hook) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end_of_run_hook(\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus))\n",
      "File \u001b[1;32mc:\\Users\\alesm\\miniconda3\\envs\\mlagents\\lib\\site-packages\\evotorch\\algorithms\\searchalgorithm.py:390\u001b[0m, in \u001b[0;36mSearchAlgorithm.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_step_datetime \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_step_datetime \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m--> 390\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_status({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_count})\n",
      "File \u001b[1;32mc:\\Users\\alesm\\miniconda3\\envs\\mlagents\\lib\\site-packages\\evotorch\\algorithms\\ga.py:1018\u001b[0m, in \u001b[0;36mCosyne._step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1015\u001b[0m to_merge\u001b[38;5;241m.\u001b[39mextend([children, permuted])\n\u001b[0;32m   1017\u001b[0m extended_population \u001b[38;5;241m=\u001b[39m SolutionBatch(merging_of\u001b[38;5;241m=\u001b[39mto_merge)\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_problem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextended_population\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_population \u001b[38;5;241m=\u001b[39m extended_population\u001b[38;5;241m.\u001b[39mtake_best(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popsize)\n",
      "File \u001b[1;32mc:\\Users\\alesm\\miniconda3\\envs\\mlagents\\lib\\site-packages\\evotorch\\core.py:2548\u001b[0m, in \u001b[0;36mProblem.evaluate\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   2544\u001b[0m must_sync_after \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sync_before()\n\u001b[0;32m   2546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_preparations()\n\u001b[1;32m-> 2548\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m must_sync_after:\n\u001b[0;32m   2551\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sync_after()\n",
      "File \u001b[1;32mc:\\Users\\alesm\\miniconda3\\envs\\mlagents\\lib\\site-packages\\evotorch\\core.py:2587\u001b[0m, in \u001b[0;36mProblem._evaluate_all\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m   2579\u001b[0m \u001b[38;5;66;03m# mapresult = self._actor_pool.map(lambda a, v: a.evaluate_batch.remote(v), list(pieces))\u001b[39;00m\n\u001b[0;32m   2580\u001b[0m \u001b[38;5;66;03m# for i, evals in enumerate(mapresult):\u001b[39;00m\n\u001b[0;32m   2581\u001b[0m \u001b[38;5;66;03m#    row_begin, row_end = pieces.indices_of(i)\u001b[39;00m\n\u001b[0;32m   2582\u001b[0m \u001b[38;5;66;03m#    batch._evdata[row_begin:row_end, :] = evals\u001b[39;00m\n\u001b[0;32m   2584\u001b[0m mapresult \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_pool\u001b[38;5;241m.\u001b[39mmap_unordered(\n\u001b[0;32m   2585\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m a, v: a\u001b[38;5;241m.\u001b[39mevaluate_batch_piece\u001b[38;5;241m.\u001b[39mremote(v[\u001b[38;5;241m0\u001b[39m], v[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(pieces))\n\u001b[0;32m   2586\u001b[0m )\n\u001b[1;32m-> 2587\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, evals \u001b[38;5;129;01min\u001b[39;00m mapresult:\n\u001b[0;32m   2588\u001b[0m     row_begin, row_end \u001b[38;5;241m=\u001b[39m pieces\u001b[38;5;241m.\u001b[39mindices_of(i)\n\u001b[0;32m   2589\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_evdata[row_begin:row_end, :] \u001b[38;5;241m=\u001b[39m evals\n",
      "File \u001b[1;32mc:\\Users\\alesm\\miniconda3\\envs\\mlagents\\lib\\site-packages\\ray\\util\\actor_pool.py:170\u001b[0m, in \u001b[0;36mActorPool.map_unordered.<locals>.get_generator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_generator\u001b[39m():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_next():\n\u001b[1;32m--> 170\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_unordered\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alesm\\miniconda3\\envs\\mlagents\\lib\\site-packages\\ray\\util\\actor_pool.py:352\u001b[0m, in \u001b[0;36mActorPool.get_next_unordered\u001b[1;34m(self, timeout, ignore_if_timedout)\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo more results to get\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# TODO(ekl) bulk wait for performance\u001b[39;00m\n\u001b[1;32m--> 352\u001b[0m res, _ \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_future_to_actor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m timeout_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimed out waiting for result\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    354\u001b[0m raise_timeout_after_ignore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alesm\\miniconda3\\envs\\mlagents\\lib\\site-packages\\ray\\_private\\auto_init_hook.py:22\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     21\u001b[0m     auto_init_ray()\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alesm\\miniconda3\\envs\\mlagents\\lib\\site-packages\\ray\\_private\\client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alesm\\miniconda3\\envs\\mlagents\\lib\\site-packages\\ray\\_private\\worker.py:2847\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[0;32m   2845\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[0;32m   2846\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m-> 2847\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from evotorch.logging import StdOutLogger\n",
    "\n",
    "StdOutLogger(searcher)\n",
    "searcher.run(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
